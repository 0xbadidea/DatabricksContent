{"cells":[{"cell_type":"markdown","source":["MLFlow Code Here. All the above is a step by step walk through, while the code below should be ran using MLFlow and the expirement we set up."],"metadata":{}},{"cell_type":"code","source":["import mlflow\nfrom mlflow.tracking import MlflowClient\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml import Pipeline\nimport datetime as dt\nfrom pyspark.ml.feature import OneHotEncoder, VectorAssembler"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["%scala\nval tags = com.databricks.logging.AttributionContext.current.tags\nval username = tags.getOrElse(com.databricks.logging.BaseTagDefinitions.TAG_USER, java.util.UUID.randomUUID.toString.replace(\"-\", \"\"))\nspark.conf.set(\"com.databricks.demo.username\", username)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tags: Map[com.databricks.logging.TagDefinition,String] = Map(TagDefinition(opId,) -&gt; HttpServer-86992dd2f73111f3, TagDefinition(opTarget,) -&gt; /notebook/168519256284520/command/168519256284556, TagDefinition(clusterMemory,) -&gt; 18432, TagDefinition(notebookId,) -&gt; 168519256284520, TagDefinition(projectName,) -&gt; webapp, TagDefinition(eventWindowTime,) -&gt; 8466893.15, TagDefinition(httpTarget,) -&gt; /notebook/168519256284520/command/168519256284556, TagDefinition(buildHash,) -&gt; &quot;&quot;, TagDefinition(browserHash,) -&gt; #notebook/168519256284520/command/168519256284553, TagDefinition(host,Host where the request is coming from.) -&gt; 10.139.64.5, TagDefinition(notebookLanguage,) -&gt; python, TagDefinition(sparkVersion,) -&gt; 5.3.x-scala2.11, TagDefinition(hostName,) -&gt; cons-webapp-1, TagDefinition(httpMethod,) -&gt; POST, TagDefinition(browserIdleTime,) -&gt; 1200, TagDefinition(browserTabId,) -&gt; 4ae3e646-b6b1-4c8b-a192-56f280f998f7, TagDefinition(sourceIpAddress,) -&gt; 73.193.17.210, TagDefinition(browserUserAgent,) -&gt; Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36, TagDefinition(orgId,) -&gt; 1559977908724754, TagDefinition(userAgent,) -&gt; Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36, TagDefinition(clusterId,) -&gt; 0703-220934-empty762, TagDefinition(rootOpId,Unique identifier for a root of a trace (tree of ops).) -&gt; 8017431669755007196_5592691618263308068_ce5a0eb6e0884288aecedb71552d6152, TagDefinition(sessionId,) -&gt; 9ce6b1371cac4b995920a0619bc7761bd178b8d8873bfb14e30ce9a9dacd64b7, TagDefinition(clusterCreator,) -&gt; Webapp, TagDefinition(clientBranchName,) -&gt; 2.100.1036, TagDefinition(clusterType,) -&gt; spot, TagDefinition(browserHasFocus,) -&gt; true, TagDefinition(userId,) -&gt; 8499602646880646, TagDefinition(browserIsHidden,) -&gt; false, TagDefinition(opType,) -&gt; HttpServer, TagDefinition(user,) -&gt; ryan.chynoweth@insight.com, TagDefinition(browserHostName,) -&gt; westus.azuredatabricks.net, TagDefinition(parentOpId,) -&gt; ServiceMain-86992dd2d7310002, TagDefinition(jettyRpcType,) -&gt; &quot;com.databricks.backend.common.rpc.InternalDriverBackendMessages$DriverBackendRequest&quot;)\nusername: String = ryan.chynoweth@insight.com\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["client = MlflowClient()\nexps = client.list_experiments()\nexp = [s for s in exps if \"/Users/{}/BikeSharing\".format(spark.conf.get(\"com.databricks.demo.username\")) in s.name][0]\nexp_id = exp.experiment_id\nartifact_location = exp.artifact_location\nrun = client.create_run(exp_id)\nrun_id = run.info.run_id "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["mlflow.start_run(run_id)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>&lt;ActiveRun: &gt;\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["try: \n  # load data\n  df = spark.read.format('delta').load(\"/mnt/delta/silver/bikeSharing/hourly\")\n  \n  # split data\n  train_df, test_df = df.randomSplit([0.7, 0.3])\n\n  # One Hot Encoding\n  mnth_encoder = OneHotEncoder(inputCol=\"mnth\", outputCol=\"encoded_mnth\")\n  hr_encoder = OneHotEncoder(inputCol=\"hr\", outputCol=\"encoded_hr\")\n  weekday_encoder = OneHotEncoder(inputCol=\"weekday\", outputCol=\"encoded_weekday\")\n\n  # set the training variables we want to use\n  train_cols = ['encoded_mnth', 'encoded_hr', 'encoded_weekday', 'temp', 'hum']\n\n  # convert cols to a single features col\n  assembler = VectorAssembler(inputCols=train_cols, outputCol=\"features\")\n\n  # Set linear regression model\n  lr = LinearRegression(featuresCol=\"features\", labelCol=\"cnt\")\n\n  # Create pipeline\n  pipeline = Pipeline(stages=[\n    mnth_encoder,\n    hr_encoder,\n    weekday_encoder,\n    assembler,\n    lr\n  ])\n\n  # fit pipeline\n  lrPipelineModel = pipeline.fit(train_df)\n\n  # write model to datetime folder and latest folder\n  lrPipelineModel.write().overwrite().save(\"{}/latest/bike_sharing_model.model\".format(artifact_location))\n  lrPipelineModel.write().overwrite().save(\"{}/year={}/month={}/day={}/bike_sharing_model.model\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n\n  # write test predictions to datetime and lastest folder\n  predictions = lrPipelineModel.transform(test_df)\n  predictions.write.format(\"parquet\").mode(\"overwrite\").save(\"{}/latest/test_predictions.parquet\".format(artifact_location))\n  predictions.write.format(\"parquet\").mode(\"overwrite\").save(\"{}/year={}/month={}/day={}/test_predictions.parquet\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n\n  # mlflow log evaluations\n  evaluator = RegressionEvaluator(labelCol = \"cnt\", predictionCol = \"prediction\")\n\n  mlflow.log_metric(\"mae\", evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"}))\n  mlflow.log_metric(\"rmse\", evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"}))\n  mlflow.log_metric(\"r2\", evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"}))\n  mlflow.set_tag(\"Model Path\", \"{}/year={}/month={}/day={}\".format(artifact_location, dt.datetime.utcnow().year, dt.datetime.utcnow().month, dt.datetime.utcnow().day))\n  \n  mlflow.end_run(status=\"FINISHED\")\n  print(\"Model training finished successfully\")\nexcept Exception as e:\n    mlflow.log_param(\"Error\", str(e))\n    mlflow.end_run(status=\"FAILED\")\n    print(\"Model training failed: {}\".format(str(e)))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model training finished successfully\n</div>"]}}],"execution_count":6}],"metadata":{"name":"03b_BikeSharingML","notebookId":168519256284520},"nbformat":4,"nbformat_minor":0}
